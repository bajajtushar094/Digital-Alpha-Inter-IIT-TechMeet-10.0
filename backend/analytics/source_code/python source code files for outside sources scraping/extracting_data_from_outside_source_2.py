# -*- coding: utf-8 -*-
"""extracting_data_from_outside_source_2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rzDlZE1r79vwu4zXUc0wOZtOkNDc9qw_
"""

import pandas as pd
from bs4 import BeautifulSoup
import re
from selenium import webdriver
import chromedriver_binary
import string

pd.options.display.float_format = '{:.0f}'.format

#function to make all values numerical (or - for NaNs)
def convert_to_numeric(column):

    first_col = [i.replace(',','') for i in column]
    second_col = [i.replace('-','') for i in first_col]
    final_col = pd.to_numeric(second_col)
    
    return final_col

ticks = pd.read_csv('cik_with_ticker2.csv')

ticker_list = list(ticks['ticker_x'])
cik_list = list(ticks['CIK'])

len(ticker_list)

ticker_list

"""not extracted - 
FICO
"""

# ticker_list_2 = ticker_list[142:]
# ticker_list_3 = ticker_list_2
# ticker_list_3.reverse()
# ticker_list_3 = ticker_list_3[3:]
# print(ticker_list_3)

# tickers_list = ['AAPL','FB']
gctr = 0 
for ticker in ticker_list:
    cik = cik_list[gctr]
    gctr = gctr + 1
    is_link = 'https://finance.yahoo.com/quote/'+str(ticker)+'/financials?p='+str(ticker)
    bs_link = 'https://finance.yahoo.com/quote/'+str(ticker)+'/balance-sheet?p='+str(ticker)
    cf_link = 'https://finance.yahoo.com/quote/'+str(ticker)+'/cash-flow?p='+str(ticker)    
    path = r"C:/Users/gitan/Downloads/chromedriver_win32/chromedriver.exe"
    driver = webdriver.Chrome(path)
    ctr = 0

    
    for link in [is_link,bs_link,cf_link]:
        driver.get(link)
        html = driver.execute_script('return document.body.innerHTML;')
        soup = BeautifulSoup(html,'lxml')

        features = soup.find_all('div', class_='D(tbr)')

        headers = []
        temp_list = []
        label_list = []
        final = []
        index = 0

        #create headers
        for item in features[0].find_all('div', class_='D(ib)'):
            headers.append(item.text)

        #statement contents
        while index <= len(features)-1:
            #filter for each line of the statement
            temp = features[index].find_all('div', class_='D(tbc)')
            for line in temp:
                #each item adding to a temporary list
                temp_list.append(line.text)
            #temp_list added to final list
            final.append(temp_list)
            #clear temp_list
            temp_list = []
            index+=1

        df = pd.DataFrame(final[1:])
        df.columns = headers

        for column in headers[1:]:
    
            df[column] = convert_to_numeric(df[column])

        strs = ['is','bs','cf']

        final_df = df.fillna('-')
        filenam = 'yahoo_extracted_annual_corrected/'+str(cik)+'_'+str(ctr)+".csv"
        ctr+=1
        final_df.to_csv(filenam)
# -*- coding: utf-8 -*-
"""02_data_processing_anmol (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1rPWM9phddrKNf8vffA6e4n4X9f2nD1_Q
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip -q install -q pandas nltk transformers

import nltk
import pandas as pd
from transformers import pipeline

nltk.download('all')

df = pd.read_csv("/content/extracted_data_10K.csv")

!pip install huggingface

df.head()

import huggingface

from transformers import AutoTokenizer, AutoModelForQuestionAnswering

tokenizer = AutoTokenizer.from_pretrained("distilbert-base-uncased-distilled-squad")

model = AutoModelForQuestionAnswering.from_pretrained("distilbert-base-uncased-distilled-squad")

QnA = pipeline("question-answering", model = model, tokenizer = tokenizer,num_workers=-1,device=0)

!nvidia-smi -L

# print(df.iloc[12]["item_7"])
ar = []
for i in range(len(df.index)):
  context = df.iloc[i]["item_7"]
  question = "How many customers are there in 2020?"
  ans = QnA({"question" : question, "context" : context})
  ar.append(ans)
  print(ans, i)

df["No_of_customers_qna_ans"] = ar

df.head()

len([x for x in ar if x['score']>0.93])

df.to_csv("extracted_data_10K_withQnA.csv", index = False)

# from transformers import AutoTokenizer, AutoModelForSequenceClassification

# tokenizer = AutoTokenizer.from_pretrained("ProsusAI/finbert")

# model = AutoModelForSequenceClassification.from_pretrained("ProsusAI/finbert")

# summarizer = pipeline('summarization', model='t5-base')

# # classifier_model_name = 'bhadresh-savani/distilbert-base-uncased-emotion'
# # classifier_emotions = ['anger', 'disgust', 'fear', 'joy', 'sadness', 'surprise']

# # classifier_model_name = 'ProsusA I/finbert'
# classifier_emotions = ['positive', 'neutral', 'negative']

# classifier = pipeline('text-classification', model=model)

def find_emotional_sentences(text, emotions, threshold):
    sentences_by_emotion = {}
    for e in emotions:
        sentences_by_emotion[e]=[]
    sentences = nltk.sent_tokenize(text)
    print(f'Document has {len(text)} characters and {len(sentences)} sentences.')
    for s in sentences:
        prediction = classifier(s)
        if (prediction[0]['label']!='neutral' and prediction[0]['score']>threshold):
            #print (f'Sentence #{sentences.index(s)}: {prediction} {s}')
            sentences_by_emotion[prediction[0]['label']].append(s)
    for e in emotions:
        print(f'{e}: {len(sentences_by_emotion[e])} sentences')
    return sentences_by_emotion

def summarize_sentences(sentences_by_emotion, min_length, max_length):
    for k in sentences_by_emotion.keys():
        if (len(sentences_by_emotion[k])!=0):
            text = ' '.join(sentences_by_emotion[k])
            summary = summarizer(text, min_length=min_length, max_length=max_length)
            print(f"{k.upper()}: {summary[0]['summary_text']}\n")

# df10k.iloc[0]["text"]

for i in range(len(df10k)):
  text = df10k.iloc[i]["text"]
  sentences_by_emotion = find_emotional_sentences(text, classifier_emotions, 0.7)
  temp = summarize_sentences(sentences_by_emotion, min_length=10, max_length=200)
  df10k["summarized"] = temp

# Allocate a pipeline for question-answering
question_answerer = pipeline('question-answering')
question_answerer({
    'question': 'What is the Newtons third law of motion?',
    'context': 'Newtonâ€™s third law of motion states that, "For every action there is equal and opposite reaction"'})

# Allocate a pipeline for question-answering
question_answerer = pipeline('question-answering')
question_answerer({
    'question': 'How many customers in 2021?',
    'context': df10k['summary'][1]})

arr = []
for i in range(len(df10k)):
  context = df10k['summary'][i]
  temp2 = question_answerer({
    'question': 'How many customers in 2021?',
    'context': context })
  px = temp2['answer']
  ans = ''
  px = str(px)
  for j in range(len(px)):
    if px[j].isnumeric()==False and px[j]!=',':
      ans = None
      break
    else:
      ans+=px[j]

  arr.append(ans)
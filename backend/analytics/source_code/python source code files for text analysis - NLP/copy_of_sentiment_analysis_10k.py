# -*- coding: utf-8 -*-
"""Copy of sentiment_analysis_10k.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/166hJadIvcj8f4DBDCWCTF3dgjDAjn_tK
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip -q install -q pandas nltk transformers

import nltk
import pandas as pd
from transformers import pipeline

nltk.download('all')

from google.colab import drive
drive.mount('/content/drive', force_remount = True)

df = pd.read_csv("/content/drive/MyDrive/10k extracted/extracted_data_10K.csv")

from google.colab import drive
drive.mount('/content/drive')

!pip install huggingface

df.head()

import huggingface

from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained("ProsusAI/finbert")

model = AutoModelForSequenceClassification.from_pretrained("ProsusAI/finbert")

senti = pipeline("sentiment-analysis", model = model, tokenizer = tokenizer,num_workers=-1,device=0)

!nvidia-smi -L

cols = df.columns

all = []
for j in range(191): 
  txt = ""
  for i in range(len(cols)):
    if cols[i]!='filename': 
      txt += str(df[cols[i]][j])
  all.append(txt)
df['all'] = all

!pip install bert-extractive-summarizer
!pip install transformers
!pip install spacy

from summarizer import Summarizer,TransformerSummarizer
bert_model = TransformerSummarizer(transformer_type="Bert",transformer_model_key="bert-base-uncased",gpu_id=0)

arr_temp = []
classifier = pipeline('sentiment-analysis', model='ProsusAI/finbert')

for i in range(len(df)):
  for j in df.columns:
    if j=='item_1' or j=='item_1A' or j=='item_3' or j=='item_7' or j=='item_7A' or j=='item_8':
      text = df[j].iloc[i]
      # sentences_by_emotion = find_emotional_sentences(text, classifier_emotions, 0.7)
      temp = bert_model(str(text), min_length=50,max_length = 500)
      ans=len(temp)
      ctr = 0
      while(len(temp)>=512 and ctr<=3):
        temp = bert_model(str(temp), min_length=50,max_length = 500)
        ctr+=1
      if(len(temp)>=512):
        temp = temp[:500]
      sentiment = classifier(str(temp))
      df[f"{j}_sentiment"]=sentiment[0]['label']
      df[f"{j}_sentiment_score"]=sentiment[0]['score']
      print(temp)
      df[f"{j}_summary"]=temp
      print('-'*50)
      print(sentiment)
      print('-'*50)
      arr_temp.append(temp)
  print(" ")
  print("*"*100)
  print(f"Completed for Row {i}")
  print("*"*100)
  print(" ")

classifier = pipeline('sentiment-analysis', model='ProsusAI/finbert')
sent = classifier('Stocks hit record highs')
sent[0]['label']

df.to_csv("summary_sentiment.csv",index=False)

df.head()

"""https://huggingface.co/ProsusAI/finbert"""
# -*- coding: utf-8 -*-
"""Copy of tables_analysis(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HsdU24JrgizzDXFi4PiSOltHGlhPPH-f
"""

import pandas as pd
import os

from google.colab import drive
drive.mount('/content/drive')

fileName = os.listdir("/content/drive/MyDrive/10k extracted/financial tables renamed")

temp = "/content/drive/MyDrive/10k extracted/financial tables renamed/" + "Financial_Report (13).xlsx"
xl = pd.ExcelFile(temp)
sheet_names = xl.sheet_names

sheet_names[0:4]

excel_data = pd.read_excel(temp, sheet_name=sheet_names)

table = excel_data["Consolidated Statements of Oper"]

# table = table[table[table.columns[1]] != "nan"]

table = table.dropna()

!pip install transformers
!pip install torch-scatter -f https://data.pyg.org/whl/torch-1.11.0+${CUDA}.html

# from transformers import AutoTokenizer, AutoModelForTableQuestionAnswering
# from transformers import pipeline

# tokenizer = AutoTokenizer.from_pretrained("google/tapas-large-finetuned-sqa")

# model = AutoModelForTableQuestionAnswering.from_pretrained("google/tapas-large-finetuned-sqa")
# tqa = pipeline(task="table-question-answering", model= model, tokenizer = tokenizer, num_workers=0,device=0)

# tqa = pipeline(task="table-question-answering", model="google/tapas-base-finetuned-wtq")

from transformers import pipeline

# # from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
# # tokenizer = AutoTokenizer.from_pretrained("nielsr/tapex-large-finetuned-wtq")
# # model = AutoModelForSeq2SeqLM.from_pretrained("nielsr/tapex-large-finetuned-wtq")

from transformers import AutoTokenizer, AutoModelForTableQuestionAnswering
tokenizer = AutoTokenizer.from_pretrained("navteca/tapas-large-finetuned-wtq")
model = AutoModelForTableQuestionAnswering.from_pretrained("navteca/tapas-large-finetuned-wtq")

tqa = pipeline(task="table-question-answering", model= model, tokenizer = tokenizer, num_workers=0,device=0)

table = table.astype(str)
# table = table.reindex(range(0, len(table)))

table = table.reset_index().drop("index", axis = 1)

# temp_table  = table.loc[[i for i in range(13)]]
temp_table = table

temp_table  = temp_table.T

temp_table = temp_table.astype(str)

temp_table.columns  = temp_table.iloc[0]

temp_table = temp_table.iloc[1:, :]

temp_table = temp_table.reset_index().drop("index", axis = 1)

temp_table["year"] = [str(2021-i) for i in range(temp_table.shape[0])]

temp_table

query = "what is the sales and marketing in 2021?"

tqa(table=temp_table, query=query)

# from transformers import BartTokenizer, BartForConditionalGeneration
# tokenizer = BartTokenizer.from_pretrained("nielsr/tapex-large-finetuned-wtq")
# model = BartForConditionalGeneration.from_pretrained("nielsr/tapex-large-finetuned-wtq")

# import abc
# import abc
# from typing import Dict, List, List


# class TableLinearize(abc.ABC):

#     PROMPT_MESSAGE = """
#         Please check that your table must follow the following format:
#         {"header": ["col1", "col2", "col3"], "rows": [["row11", "row12", "row13"], ["row21", "row22", "row23"]]}
#     """

#     def process_table(self, table_content: Dict) -> str:
#         """
#         Given a table, TableLinearize aims at converting it into a flatten sequence with special symbols.
#         """
#         pass

#     def process_header(self, headers: List):
#         """
#         Given a list of headers, TableLinearize aims at converting it into a flatten sequence with special symbols.
#         """
#         pass

#     def process_row(self, row: List, row_index: int):
#         """
#         Given a row, TableLinearize aims at converting it into a flatten sequence with special symbols.
#         """
#         pass


# class IndexedRowTableLinearize(TableLinearize):
#     """
#     FORMAT: col: col1 | col2 | col 3 row 1 : val1 | val2 | val3 row 2 : ...
#     """

#     def process_table(self, table_content: Dict):
#         """
#         Given a table, TableLinearize aims at converting it into a flatten sequence with special symbols.
#         """
#         assert "header" in table_content and "rows" in table_content, self.PROMPT_MESSAGE
#         # process header
#         _table_str = self.process_header(table_content["header"]) + " "
#         # process rows
#         for i, row_example in enumerate(table_content["rows"]):
#             # NOTE: the row should start from row 1 instead of 0
#             _table_str += self.process_row(row_example, row_index=i + 1) + " "
#         return _table_str.strip()

#     def process_header(self, headers: List):
#         """
#         Given a list of headers, TableLinearize aims at converting it into a flatten sequence with special symbols.
#         """
#         return "col : " + " | ".join(headers)

#     def process_row(self, row: List, row_index: int):
#         """
#         Given a row, TableLinearize aims at converting it into a flatten sequence with special symbols.
#         """
#         row_str = ""
#         row_cell_values = []
#         for cell_value in row:
#             if isinstance(cell_value, int):
#                 row_cell_values.append(str(cell_value))
#             else:
#                 row_cell_values.append(cell_value)
#         row_str += " | ".join(row_cell_values)
#         return "row " + str(row_index) + " : " + row_str


# table_dict = {"header": list(temp_table.columns), "rows": [list(row.values) for i,row in temp_table.iterrows()]}

# linearizer = IndexedRowTableLinearize()
# linear_table = linearizer.process_table(table_dict)

# question = "what are the operating cost?"
# joint_input = question + " " + linear_table

# # encode 
# encoding = tokenizer(joint_input, return_tensors="pt")

# # forward pass
# outputs = model.generate(**encoding)

# # decode
# tokenizer.batch_decode(outputs, skip_special_tokens=True)


# -*- coding: utf-8 -*-
"""8k_sentiment.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1e8FNmTrVptVfmsTRcG7EaaGVrpaL1dWB
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip -q install -q pandas nltk transformers

import nltk
import pandas as pd
from transformers import pipeline

nltk.download('all')

from google.colab import drive
drive.mount('/content/drive', force_remount = True)

!pip install huggingface

!nvidia-smi -L

!pip install bert-extractive-summarizer
!pip install transformers
!pip install spacy

from summarizer import Summarizer,TransformerSummarizer
bert_model = TransformerSummarizer(transformer_type="Bert",transformer_model_key="bert-base-uncased",gpu_id=0)

import os
import json

directory = "/content/drive/MyDrive/10k extracted/EXTRACTED_FILINGS/"

file_names = []
ciks = []
dates = []
texts = []

for filename in os.listdir(directory):
    ff = os.path.join(directory, filename)
    # checking if it is a file
    if os.path.isfile(ff):
        f = open(str(ff),"r")
        data = json.loads(f.read())
        if data["filing_type"]!="8-K":
          continue
        file_names.append(data["filename"])
        ciks.append(data["cik"])
        dates.append(data["filing_date"])
        text = ""
        for a,b in data.items():
          if(str(a)[0:4]=="item"):
            text = text + str(b)
        texts.append(text)

import pandas as pd
dict = {'filename': file_names, 'cik': ciks, 'date': dates, 'text':texts} 
df = pd.DataFrame(dict)
df

classifier = pipeline('sentiment-analysis', model='ProsusAI/finbert')
arr_temp=[]
summarylist = []
sentlist = []
scorelist = []
polarity_list = []
for i in range(len(df)):
  text = df['text'].iloc[i]
  # sentences_by_emotion = find_emotional_sentences(text, classifier_emotions, 0.7)
  temp = text
  # polarr=[]
  # blob = TextBlob(text)
  # for sentence in blob.sentences:
  #     polarr.append([sentence.sentiment.polarity])
  
  # df['polarity_score'][i]=(np.array(polarr).mean())
  ans=len(temp)
  ctr = 0
  if ans>=512:
    while(len(temp)>=512 and ctr<=2):
      temp = bert_model(str(temp), min_length=50,max_length = 500)
      ctr+=1
  if(len(temp)>=512):
    temp = temp[:500]
  sentiment = classifier(str(temp))
  sentlist.append(sentiment[0]['label'])
  scorelist.append(sentiment[0]['score'])
  print(temp)
  summarylist.append(temp)
  print('-'*50)
  print(sentiment)
  print('-'*50)
  arr_temp.append(temp)
  print(" ")
  print("*"*100)
  print(f"Completed for Row {i}")
  print("*"*100)
  print(" ")



df['summary']=summarylist
df['sentiment']=sentlist
df['sentiment score']=scorelist

df

df.to_csv('sentiment_8k_calculated.csv')

import pandas as pd
df22 = pd.read_csv('/content/drive/MyDrive/10k extracted/sentiment_8k_calculated.csv')

import numpy as np

!pip install TextBlob

import nltk
nltk.download("punkt")

import numpy as np
from textblob import TextBlob
df = df22
polarity_list = []
for i in range(len(df)):
  text = df['text'].iloc[i]
  # sentences_by_emotion = find_emotional_sentences(text, classifier_emotions, 0.7)
  temp = text
  polarr=[]
  blob = TextBlob(text)
  for sentence in blob.sentences:
      polarr.append([sentence.sentiment.polarity])
  
  polarity_list.append(np.array(polarr).mean())
  print(np.array(polarr).mean())
  print(" ")
  print("*"*100)
  print(f"Completed for Row {i}")
  print("*"*100)
  print(" ")

df.to_csv('sentiment_8k_polarity_included.csv')

df['polarity'] = polarity_list

df

